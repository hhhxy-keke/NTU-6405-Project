import streamlit as st
import torch
from sympy.physics.control.control_plots import plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from PIL import Image
from peft import PeftModel

st.set_page_config(
    page_title="6405 Group 16 Project",
    layout="wide"
)
st.title("ğŸ¤–6405 Group 16: Online Prediction Platform for BERT and its Variant Models")
st.write("Please select a model, enter text, and view the prediction results and the model's training performance metrics.")


MODEL_PATHS = {
    "BERT_SentimentAnalysis": "model/bert_base_sentiment",
}

BASE_MODEL = "bert-base-uncased"

# åŠ è½½æ¨¡å‹å‡½æ•°ï¼ˆç¼“å­˜ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
@st.cache_resource
def load_models():
    models = {}
    tokenizers = {}
    for name, adapter_path in MODEL_PATHS.items():
        base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=2)
        model = PeftModel.from_pretrained(base_model, adapter_path, is_trainable=False)
        model.eval()  # æ¨ç†æ¨¡å¼

        models[name] = model
        tokenizers[name] = AutoTokenizer.from_pretrained(BASE_MODEL)
    return models, tokenizers, MODEL_PATHS


# åŠ è½½æ··æ·†çŸ©é˜µå›¾ç‰‡ï¼ˆPNGï¼‰
def load_confusion_matrix(model_name):
    img_path = f"metrics/confusion_{model_name}.png"
    img = Image.open(img_path)
    return img

# åŠ è½½
models, tokenizers, model_names = load_models()

# ç”¨æˆ·è¾“å…¥ä¸æ¨¡å‹é€‰æ‹©
with st.sidebar:  # ä¾§è¾¹æ æ”¾è¾“å…¥æ§ä»¶
    st.subheader("Sentiment Analysis")
    sentiment_models = ["BERT", "ROBERTA"]
    sentiment_model_selected = st.selectbox("Select Sentiment Model:", sentiment_models)
    sentiment_input = st.text_area(
        "Enter text for sentiment analysis:",
        "Please enter a sentence with emotional connotations."
    )

    st.subheader("News Topic Categorization")
    news_models = ["BERT", "ROBERTA"]
    news_model_selected = st.selectbox("Select News Model:", news_models)
    news_input = st.text_area(
        "Enter text for news topic categorization:",
        "Please enter a sentence belonging to 'World', 'Sports', 'Business', or 'Sci/Tech'."
    )


    submit = st.button("Start Predicting")


# æ¨¡å‹é¢„æµ‹ä¸ç»“æœå±•ç¤º
if submit:
    # æƒ…æ„Ÿåˆ†æé¢„æµ‹
    if sentiment_input and sentiment_model_selected:
        model = models["BERT_SentimentAnalysis"] if sentiment_model_selected == "BERT" else models["ROBERTA_SentimentAnalysis"]
        tokenizer = tokenizers["BERT_SentimentAnalysis"] if sentiment_model_selected == "BERT" else tokenizers["ROBERTA_SentimentAnalysis"]

        inputs = tokenizer(sentiment_input, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=1).item()

        st.subheader("Sentiment Analysis Prediction")
        result_map = {0: "è´Ÿé¢", 1: "æ­£é¢"}  # æ ¹æ®æ¨¡å‹æ ‡ç­¾è°ƒæ•´
        st.success(f"{sentiment_model_selected} é¢„æµ‹ç»“æœ: {result_map[predictions]}")

        # æ··æ·†çŸ©é˜µå±•ç¤º
        st.subheader(f"{sentiment_model_selected} æƒ…æ„Ÿåˆ†ææ··æ·†çŸ©é˜µ")
        conf_matrix_img = load_confusion_matrix("BERT_SentimentAnalysis")  # æˆ– ROBERTA çš„å›¾ç‰‡è·¯å¾„
        st.image(conf_matrix_img, use_column_width=True)

    # æ–°é—»åˆ†ç±»é¢„æµ‹
    if news_input and news_model_selected:
        model = models["BERT_News"] if news_model_selected == "BERT" else models["ROBERTA_News"]
        tokenizer = tokenizers["BERT_News"] if news_model_selected == "BERT" else tokenizers["ROBERTA_News"]

        inputs = tokenizer(news_input, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=1).item()

        st.subheader("News Topic Categorization Prediction")
        topic_map = {0: "World", 1: "Sports", 2: "Business", 3: "Sci/Tech"}  # æŒ‰ä½ çš„æ ‡ç­¾æ˜ å°„
        st.success(f"{news_model_selected} é¢„æµ‹ç»“æœ: {topic_map[predictions]}")

        # æ··æ·†çŸ©é˜µå±•ç¤º
        st.subheader(f"{news_model_selected} æ–°é—»åˆ†ç±»æ··æ·†çŸ©é˜µ")
        conf_matrix_img = load_confusion_matrix("BERT_News")  # æˆ– ROBERTA çš„å›¾ç‰‡è·¯å¾„
        st.image(conf_matrix_img, use_column_width=True)


# # 2ï¸âƒ£ å±•ç¤ºæ€»ä½“æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
# metrics_file = "metrics/metrics.csv"
# if os.path.exists(metrics_file):
#     df = pd.read_csv(metrics_file)
#     st.bar_chart(df.set_index("model")["accuracy"])

st.markdown("---")
st.write("BERT is trained on google-bert/bert-base-uncased.\n"
         "ROBERTA is trained on FacebookAI/roberta-base. \n"
         "Deploy using Streamlit \n"
         "Authors: NTU EEE 6405 Group 16: Zeng Jiabo, Fu Wanting, Hou Xinyu, Wang Di, Wang Jianyu, Xie Debin (Sort by first letter of surname)")